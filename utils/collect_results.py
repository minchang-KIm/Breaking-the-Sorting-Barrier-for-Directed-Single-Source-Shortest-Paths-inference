#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê²°ê³¼ ìˆ˜ì§‘ ìœ í‹¸ë¦¬í‹° / Result Collection Utility

ë²¤ì¹˜ë§ˆí¬ ì¶œë ¥ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ë…¼ë¬¸ìš© CSV í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
Parses benchmark output files and converts them to CSV format for paper.

ì‚¬ìš©ë²• / Usage:
    python collect_results.py --input results/raw/ --output results/processed/

ì‘ì„±ì / Author: Research Team
ë‚ ì§œ / Date: 2025-11-17
"""

import os
import re
import json
import pandas as pd
import numpy as np
from pathlib import Path
import argparse
from typing import Dict, List, Tuple
from tqdm import tqdm

class BenchmarkResultCollector:
    """
    ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìˆ˜ì§‘ ë° ì²˜ë¦¬ í´ë˜ìŠ¤
    Benchmark result collection and processing class
    """

    def __init__(self, input_dir: str, output_dir: str):
        """
        ì´ˆê¸°í™” / Initialize

        Args:
            input_dir: ì›ë³¸ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë””ë ‰í† ë¦¬
            output_dir: ì²˜ë¦¬ëœ CSV ì¶œë ¥ ë””ë ‰í† ë¦¬
        """
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # ì•Œê³ ë¦¬ì¦˜ ì´ë¦„ ë§¤í•‘ / Algorithm name mapping
        self.algorithm_names = {
            'seq': 'Duan et al. (ìˆœì°¨)',
            'dijkstra': 'Dijkstra',
            'bellman_ford': 'Bellman-Ford',
            'openmp': 'Duan et al. (OpenMP)',
            'mpi': 'Duan et al. (MPI)',
            'cuda': 'Duan et al. (CUDA)',
            'mgap': 'MGAP (ì œì•ˆ ê¸°ë²•)'
        }

    def parse_benchmark_file(self, filepath: Path) -> List[Dict]:
        """
        ë²¤ì¹˜ë§ˆí¬ ì¶œë ¥ íŒŒì¼ íŒŒì‹± / Parse benchmark output file

        ì˜ˆìƒ í˜•ì‹ / Expected format:
            Algorithm: dijkstra
            Dataset: road_network_1M.txt
            Vertices: 1000000
            Edges: 5000000
            Execution Time: 1234.56 ms
            Memory Usage: 512.34 MB
            ...

        Returns:
            íŒŒì‹±ëœ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        current_result = {}

        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()

                # í‚¤: ê°’ í˜•ì‹ íŒŒì‹±
                if ':' in line:
                    key, value = line.split(':', 1)
                    key = key.strip()
                    value = value.strip()

                    # ìˆ«ì ì¶”ì¶œ
                    if 'Time' in key:
                        # "1234.56 ms" -> 1234.56
                        match = re.search(r'([\d.]+)', value)
                        if match:
                            current_result[key] = float(match.group(1))
                    elif 'Vertices' in key or 'Edges' in key:
                        match = re.search(r'([\d,]+)', value.replace(',', ''))
                        if match:
                            current_result[key] = int(match.group(1))
                    elif 'Memory' in key:
                        # "512.34 MB" -> 512.34
                        match = re.search(r'([\d.]+)', value)
                        if match:
                            current_result[key] = float(match.group(1))
                    elif 'Speedup' in key:
                        match = re.search(r'([\d.]+)x', value)
                        if match:
                            current_result[key] = float(match.group(1))
                    else:
                        current_result[key] = value

                # ë¹ˆ ì¤„ì´ ê²°ê³¼ êµ¬ë¶„ì / Empty line separates results
                elif line == '' and current_result:
                    results.append(current_result.copy())
                    current_result = {}

            # ë§ˆì§€ë§‰ ê²°ê³¼ ì¶”ê°€
            if current_result:
                results.append(current_result)

        return results

    def create_performance_summary(self, all_results: List[Dict]) -> pd.DataFrame:
        """
        ì„±ëŠ¥ ìš”ì•½ í‘œ ìƒì„± / Create performance summary table

        Returns:
            DataFrame with columns: Algorithm, Dataset, Vertices, Edges, Time(ms), Speedup, MTEPS
        """
        data = []

        for result in all_results:
            row = {
                'ì•Œê³ ë¦¬ì¦˜ (Algorithm)': self.algorithm_names.get(
                    result.get('Algorithm', ''),
                    result.get('Algorithm', 'Unknown')
                ),
                'ë°ì´í„°ì…‹ (Dataset)': result.get('Dataset', 'Unknown'),
                'ì •ì  ìˆ˜ (Vertices)': result.get('Vertices', 0),
                'ê°„ì„  ìˆ˜ (Edges)': result.get('Edges', 0),
                'ì‹¤í–‰ ì‹œê°„ (Time, ms)': result.get('Execution Time', 0.0),
                'ì†ë„ í–¥ìƒ (Speedup)': result.get('Speedup', 1.0),
                'ì²˜ë¦¬ëŸ‰ (MTEPS)': result.get('Throughput (MTEPS)', 0.0)
            }
            data.append(row)

        df = pd.DataFrame(data)

        # MTEPS ê³„ì‚° (edges / (time_ms * 1000))
        df['ì²˜ë¦¬ëŸ‰ (MTEPS)'] = df['ê°„ì„  ìˆ˜ (Edges)'] / (df['ì‹¤í–‰ ì‹œê°„ (Time, ms)'] * 1000)

        return df

    def create_speedup_table(self, all_results: List[Dict]) -> pd.DataFrame:
        """
        ì†ë„ í–¥ìƒ í‘œ ìƒì„± / Create speedup table

        ê° ë°ì´í„°ì…‹ë³„ë¡œ ì•Œê³ ë¦¬ì¦˜ ê°„ ì†ë„ í–¥ìƒ ë¹„êµ
        Compare speedup across algorithms for each dataset
        """
        # ë°ì´í„°ì…‹ë³„ë¡œ ê·¸ë£¹í™”
        dataset_groups = {}
        for result in all_results:
            dataset = result.get('Dataset', 'Unknown')
            if dataset not in dataset_groups:
                dataset_groups[dataset] = []
            dataset_groups[dataset].append(result)

        # ê° ë°ì´í„°ì…‹ì— ëŒ€í•´ ì†ë„ í–¥ìƒ ê³„ì‚°
        data = []
        for dataset, results in dataset_groups.items():
            # ìˆœì°¨ ë² ì´ìŠ¤ë¼ì¸ ì°¾ê¸°
            baseline_time = None
            for r in results:
                if r.get('Algorithm') == 'seq' or 'Dijkstra' in r.get('Algorithm', ''):
                    baseline_time = r.get('Execution Time', 1.0)
                    break

            if baseline_time is None:
                # ë² ì´ìŠ¤ë¼ì¸ì´ ì—†ìœ¼ë©´ ê°€ì¥ ëŠë¦° ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©
                baseline_time = max(r.get('Execution Time', 1.0) for r in results)

            for r in results:
                algo = self.algorithm_names.get(r.get('Algorithm', ''), r.get('Algorithm', 'Unknown'))
                time_ms = r.get('Execution Time', 1.0)
                speedup = baseline_time / time_ms if time_ms > 0 else 1.0

                data.append({
                    'ë°ì´í„°ì…‹ (Dataset)': dataset,
                    'ì•Œê³ ë¦¬ì¦˜ (Algorithm)': algo,
                    'ì‹¤í–‰ ì‹œê°„ (ms)': time_ms,
                    'ì†ë„ í–¥ìƒ (Speedup)': speedup,
                    'íš¨ìœ¨ (Efficiency, %)': 0.0  # ë‚˜ì¤‘ì— ê³„ì‚°
                })

        return pd.DataFrame(data)

    def create_communication_analysis(self, all_results: List[Dict]) -> pd.DataFrame:
        """
        í†µì‹  ë¶„ì„ í‘œ ìƒì„± / Create communication analysis table

        Multi-GPU ê²°ê³¼ì— ëŒ€í•œ í†µì‹  ë©”íŠ¸ë¦­
        Communication metrics for Multi-GPU results
        """
        data = []

        for result in all_results:
            algo = result.get('Algorithm', '')

            # Multi-GPU ì•Œê³ ë¦¬ì¦˜ë§Œ í¬í•¨
            if algo in ['mpi', 'cuda', 'mgap']:
                row = {
                    'ì•Œê³ ë¦¬ì¦˜ (Algorithm)': self.algorithm_names.get(algo, algo),
                    'ë°ì´í„°ì…‹ (Dataset)': result.get('Dataset', 'Unknown'),
                    'GPU ìˆ˜ (# GPUs)': result.get('GPU Count', 1),
                    'ê°„ì„  ì ˆë‹¨ (Edge-Cut)': result.get('Edge-Cut', 0),
                    'í†µì‹ ëŸ‰ (MB)': result.get('Communication Volume (MB)', 0.0),
                    'í†µì‹  ì‹œê°„ (ms)': result.get('Communication Time (ms)', 0.0),
                    'í†µì‹  ë¹„ìœ¨ (%)': result.get('Communication Ratio (%)', 0.0),
                    'ëŒ€ì—­í­ (GB/s)': result.get('Bandwidth (GB/s)', 0.0)
                }
                data.append(row)

        return pd.DataFrame(data)

    def create_scalability_data(self, all_results: List[Dict]) -> pd.DataFrame:
        """
        í™•ì¥ì„± ë°ì´í„° í‘œ ìƒì„± / Create scalability data table

        GPU ìˆ˜ì— ë”°ë¥¸ strong/weak scaling ë°ì´í„°
        Strong/weak scaling data by GPU count
        """
        data = []

        # GPU ìˆ˜ë³„ë¡œ ê·¸ë£¹í™”
        for result in all_results:
            algo = result.get('Algorithm', '')
            if algo in ['cuda', 'mgap']:
                gpu_count = result.get('GPU Count', 1)
                time_ms = result.get('Execution Time', 0.0)

                data.append({
                    'ì•Œê³ ë¦¬ì¦˜ (Algorithm)': self.algorithm_names.get(algo, algo),
                    'ë°ì´í„°ì…‹ (Dataset)': result.get('Dataset', 'Unknown'),
                    'GPU ìˆ˜ (# GPUs)': gpu_count,
                    'ì‹¤í–‰ ì‹œê°„ (ms)': time_ms,
                    'ì´ìƒì  ì‹œê°„ (ms)': 0.0,  # ë‚˜ì¤‘ì— ê³„ì‚°
                    'ì†ë„ í–¥ìƒ (Speedup)': 0.0,  # ë‚˜ì¤‘ì— ê³„ì‚°
                    'íš¨ìœ¨ (Efficiency, %)': 0.0  # ë‚˜ì¤‘ì— ê³„ì‚°
                })

        df = pd.DataFrame(data)

        # ê° ë°ì´í„°ì…‹ë³„ë¡œ 1 GPU ë² ì´ìŠ¤ë¼ì¸ìœ¼ë¡œ ê³„ì‚°
        for dataset in df['ë°ì´í„°ì…‹ (Dataset)'].unique():
            mask = df['ë°ì´í„°ì…‹ (Dataset)'] == dataset
            baseline_time = df[mask & (df['GPU ìˆ˜ (# GPUs)'] == 1)]['ì‹¤í–‰ ì‹œê°„ (ms)'].values

            if len(baseline_time) > 0:
                baseline = baseline_time[0]
                df.loc[mask, 'ì´ìƒì  ì‹œê°„ (ms)'] = baseline / df.loc[mask, 'GPU ìˆ˜ (# GPUs)']
                df.loc[mask, 'ì†ë„ í–¥ìƒ (Speedup)'] = baseline / df.loc[mask, 'ì‹¤í–‰ ì‹œê°„ (ms)']
                df.loc[mask, 'íš¨ìœ¨ (Efficiency, %)'] = (
                    df.loc[mask, 'ì†ë„ í–¥ìƒ (Speedup)'] / df.loc[mask, 'GPU ìˆ˜ (# GPUs)'] * 100
                )

        return df

    def create_memory_usage_table(self, all_results: List[Dict]) -> pd.DataFrame:
        """
        ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í‘œ ìƒì„± / Create memory usage table
        """
        data = []

        for result in all_results:
            row = {
                'ì•Œê³ ë¦¬ì¦˜ (Algorithm)': self.algorithm_names.get(
                    result.get('Algorithm', ''),
                    result.get('Algorithm', 'Unknown')
                ),
                'ë°ì´í„°ì…‹ (Dataset)': result.get('Dataset', 'Unknown'),
                'ì •ì  ìˆ˜ (Vertices)': result.get('Vertices', 0),
                'ê°„ì„  ìˆ˜ (Edges)': result.get('Edges', 0),
                'CPU ë©”ëª¨ë¦¬ (MB)': result.get('Memory Usage (MB)', 0.0),
                'GPU ë©”ëª¨ë¦¬ (MB)': result.get('GPU Memory (MB)', 0.0),
                'ì´ ë©”ëª¨ë¦¬ (MB)': result.get('Total Memory (MB)', 0.0),
                'ë©”ëª¨ë¦¬ íš¨ìœ¨ (%)': 0.0  # ì´ë¡ ê°’ ëŒ€ë¹„
            }

            # ì´ë¡ ì  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: O(n + m) * sizeof(data)
            # ì •ì : 8 bytes (ê±°ë¦¬) + 4 bytes (predecessor)
            # ê°„ì„ : 4 bytes (target) + 8 bytes (weight)
            theoretical = (row['ì •ì  ìˆ˜ (Vertices)'] * 12 + row['ê°„ì„  ìˆ˜ (Edges)'] * 12) / (1024 * 1024)
            if row['ì´ ë©”ëª¨ë¦¬ (MB)'] > 0:
                row['ë©”ëª¨ë¦¬ íš¨ìœ¨ (%)'] = (theoretical / row['ì´ ë©”ëª¨ë¦¬ (MB)']) * 100

            data.append(row)

        return pd.DataFrame(data)

    def collect_all_results(self) -> Dict[str, pd.DataFrame]:
        """
        ëª¨ë“  ê²°ê³¼ ìˆ˜ì§‘ ë° í‘œ ìƒì„± / Collect all results and create tables

        Returns:
            ê° í‘œì˜ ì´ë¦„ì„ í‚¤ë¡œ í•˜ëŠ” DataFrame ë”•ì…”ë„ˆë¦¬
        """
        print("ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìˆ˜ì§‘ ì¤‘... / Collecting benchmark results...")

        # ëª¨ë“  ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
        result_files = list(self.input_dir.glob('**/*.txt')) + \
                      list(self.input_dir.glob('**/*.log')) + \
                      list(self.input_dir.glob('**/*.json'))

        all_results = []

        for filepath in tqdm(result_files, desc="íŒŒì‹± ì¤‘ / Parsing"):
            if filepath.suffix == '.json':
                # JSON íŒŒì¼ ì§ì ‘ ë¡œë“œ
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, list):
                        all_results.extend(data)
                    else:
                        all_results.append(data)
            else:
                # í…ìŠ¤íŠ¸ íŒŒì¼ íŒŒì‹±
                parsed = self.parse_benchmark_file(filepath)
                all_results.extend(parsed)

        print(f"âœ… {len(all_results)}ê°œ ê²°ê³¼ ìˆ˜ì§‘ ì™„ë£Œ / Collected {len(all_results)} results")

        # ê° í‘œ ìƒì„±
        tables = {}

        print("ğŸ“ˆ ì„±ëŠ¥ ìš”ì•½ í‘œ ìƒì„± ì¤‘... / Creating performance summary...")
        tables['performance_summary'] = self.create_performance_summary(all_results)

        print("âš¡ ì†ë„ í–¥ìƒ í‘œ ìƒì„± ì¤‘... / Creating speedup table...")
        tables['speedup_table'] = self.create_speedup_table(all_results)

        print("ğŸ“¡ í†µì‹  ë¶„ì„ í‘œ ìƒì„± ì¤‘... / Creating communication analysis...")
        tables['communication_analysis'] = self.create_communication_analysis(all_results)

        print("ğŸ“Š í™•ì¥ì„± ë°ì´í„° ìƒì„± ì¤‘... / Creating scalability data...")
        tables['scalability_data'] = self.create_scalability_data(all_results)

        print("ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í‘œ ìƒì„± ì¤‘... / Creating memory usage table...")
        tables['memory_usage'] = self.create_memory_usage_table(all_results)

        return tables

    def save_tables(self, tables: Dict[str, pd.DataFrame]):
        """
        ëª¨ë“  í‘œë¥¼ CSVë¡œ ì €ì¥ / Save all tables to CSV
        """
        print("\nğŸ’¾ CSV íŒŒì¼ ì €ì¥ ì¤‘... / Saving CSV files...")

        for name, df in tables.items():
            output_path = self.output_dir / f"{name}.csv"
            df.to_csv(output_path, index=False, encoding='utf-8-sig')
            print(f"  âœ… {output_path}")

        # ìš”ì•½ í†µê³„ë„ ì €ì¥
        summary_path = self.output_dir / "summary_statistics.txt"
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½ í†µê³„ / Benchmark Result Summary Statistics\n")
            f.write("=" * 80 + "\n\n")

            for name, df in tables.items():
                f.write(f"\n{'=' * 80}\n")
                f.write(f"{name.upper()}\n")
                f.write(f"{'=' * 80}\n")
                f.write(f"\ní–‰ ê°œìˆ˜ / Row count: {len(df)}\n")
                f.write(f"ì—´ ê°œìˆ˜ / Column count: {len(df.columns)}\n\n")
                f.write("ê¸°ìˆ  í†µê³„ / Descriptive statistics:\n")
                f.write(str(df.describe()) + "\n")

        print(f"  âœ… {summary_path}")
        print("\nâœ… ëª¨ë“  ê²°ê³¼ ì €ì¥ ì™„ë£Œ! / All results saved successfully!")

def main():
    """ë©”ì¸ í•¨ìˆ˜ / Main function"""
    parser = argparse.ArgumentParser(
        description='ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìˆ˜ì§‘ ë° CSV ë³€í™˜ / Collect benchmark results and convert to CSV',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì œ / Examples:
  python collect_results.py --input results/raw --output results/processed
  python collect_results.py -i ../results -o ../paper_results
        """
    )

    parser.add_argument(
        '--input', '-i',
        type=str,
        default='results/raw',
        help='ì›ë³¸ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë””ë ‰í† ë¦¬ / Input directory with raw benchmark results'
    )

    parser.add_argument(
        '--output', '-o',
        type=str,
        default='results/processed',
        help='ì²˜ë¦¬ëœ CSV ì¶œë ¥ ë””ë ‰í† ë¦¬ / Output directory for processed CSV files'
    )

    args = parser.parse_args()

    print("=" * 80)
    print("ğŸ“Š SSSP ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìˆ˜ì§‘ ìœ í‹¸ë¦¬í‹°")
    print("   SSSP Benchmark Result Collection Utility")
    print("=" * 80)
    print(f"\nì…ë ¥ ë””ë ‰í† ë¦¬ / Input directory: {args.input}")
    print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬ / Output directory: {args.output}\n")

    # ê²°ê³¼ ìˆ˜ì§‘ê¸° ìƒì„±
    collector = BenchmarkResultCollector(args.input, args.output)

    # ëª¨ë“  ê²°ê³¼ ìˆ˜ì§‘ ë° í‘œ ìƒì„±
    tables = collector.collect_all_results()

    # CSVë¡œ ì €ì¥
    collector.save_tables(tables)

    print("\n" + "=" * 80)
    print("ğŸ‰ ì™„ë£Œ! / Done!")
    print("=" * 80)

if __name__ == '__main__':
    main()
