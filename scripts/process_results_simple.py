#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê°„ë‹¨í•œ ê²°ê³¼ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ (ì˜ì¡´ì„± ì—†ìŒ)
Simple Results Processing (No dependencies)

JSON ê²°ê³¼ë¥¼ CSVì™€ Markdown í‘œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
"""

import json
import os
from collections import defaultdict

def json_to_csv(data, output_file):
    """JSONì„ CSVë¡œ ë³€í™˜"""
    if not data:
        return

    # í—¤ë” ì¶”ì¶œ
    headers = list(data[0].keys())

    with open(output_file, 'w', encoding='utf-8-sig') as f:
        # í—¤ë” ì‘ì„±
        f.write(','.join(headers) + '\n')

        # ë°ì´í„° ì‘ì„±
        for record in data:
            row = []
            for header in headers:
                value = record.get(header, '')
                # ì‰¼í‘œê°€ í¬í•¨ëœ ê²½ìš° ë”°ì˜´í‘œë¡œ ê°ì‹¸ê¸°
                if isinstance(value, str) and ',' in value:
                    row.append(f'"{value}"')
                else:
                    row.append(str(value))
            f.write(','.join(row) + '\n')

def json_to_markdown_table(data, output_file, title="Table"):
    """JSONì„ Markdown í‘œë¡œ ë³€í™˜"""
    if not data:
        return

    headers = list(data[0].keys())

    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(f"# {title}\n\n")

        # í—¤ë”
        f.write("| " + " | ".join(headers) + " |\n")
        f.write("| " + " | ".join(['---'] * len(headers)) + " |\n")

        # ë°ì´í„°
        for record in data:
            row = [str(record.get(h, '')) for h in headers]
            f.write("| " + " | ".join(row) + " |\n")

        f.write("\n")

def create_performance_summary(data):
    """ì„±ëŠ¥ ìš”ì•½ í‘œ ìƒì„±"""
    # ì•Œê³ ë¦¬ì¦˜ë³„ë¡œ ê·¸ë£¹í™”
    algo_groups = defaultdict(list)
    for record in data:
        algo = record.get('Algorithm', 'unknown')
        algo_groups[algo].append(record)

    summary = []
    for algo, records in sorted(algo_groups.items()):
        avg_time = sum(r.get('Execution Time (ms)', 0) for r in records) / len(records)
        avg_speedup = sum(r.get('Speedup', 0) for r in records) / len(records)
        avg_throughput = sum(r.get('Throughput (MTEPS)', 0) for r in records) / len(records)

        summary.append({
            'ì•Œê³ ë¦¬ì¦˜ (Algorithm)': algo,
            'í‰ê·  ì‹¤í–‰ ì‹œê°„ (ms)': round(avg_time, 2),
            'í‰ê·  ì†ë„ í–¥ìƒ (Speedup)': round(avg_speedup, 2),
            'í‰ê·  ì²˜ë¦¬ëŸ‰ (MTEPS)': round(avg_throughput, 3),
            'í…ŒìŠ¤íŠ¸ íšŸìˆ˜': len(records)
        })

    return summary

def create_dataset_summary(data):
    """ë°ì´í„°ì…‹ë³„ ìš”ì•½"""
    dataset_groups = defaultdict(list)
    for record in data:
        dataset = record.get('Dataset', 'unknown')
        dataset_groups[dataset].append(record)

    summary = []
    for dataset, records in sorted(dataset_groups.items()):
        first_record = records[0]

        summary.append({
            'ë°ì´í„°ì…‹ (Dataset)': dataset,
            'ì •ì  ìˆ˜ (Vertices)': first_record.get('Vertices', 0),
            'ê°„ì„  ìˆ˜ (Edges)': first_record.get('Edges', 0),
            'ìœ í˜• (Type)': first_record.get('Dataset Type', 'unknown'),
            'í…ŒìŠ¤íŠ¸ ì•Œê³ ë¦¬ì¦˜ ìˆ˜': len(records)
        })

    return summary

def create_comparison_table(data):
    """ì£¼ìš” ì•Œê³ ë¦¬ì¦˜ ë¹„êµ í‘œ"""
    # ëŒ€í‘œ ë°ì´í„°ì…‹ ì„ íƒ (ì¤‘ê°„ í¬ê¸°)
    target_dataset = "graph_medium_100Kv_500Ke"

    filtered = [r for r in data if r.get('Dataset') == target_dataset]

    if not filtered:
        filtered = data[:9]  # ì²˜ìŒ 9ê°œ

    comparison = []
    for record in filtered:
        comparison.append({
            'ì•Œê³ ë¦¬ì¦˜': record.get('Algorithm', ''),
            'ì‹¤í–‰ ì‹œê°„ (ms)': record.get('Execution Time (ms)', 0),
            'ì†ë„ í–¥ìƒ': record.get('Speedup', 0),
            'ì²˜ë¦¬ëŸ‰ (MTEPS)': record.get('Throughput (MTEPS)', 0),
            'ë©”ëª¨ë¦¬ (MB)': record.get('Total Memory (MB)', 0)
        })

    return comparison

def generate_ascii_bar_chart(data, key, title, max_width=60):
    """ASCII ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„±"""
    if not data:
        return ""

    output = [f"\n{title}", "=" * max_width, ""]

    # ìµœëŒ€ê°’ ì°¾ê¸°
    max_value = max(r[key] for r in data)

    for record in data:
        name = str(record.get('ì•Œê³ ë¦¬ì¦˜', record.get('Algorithm', 'Unknown')))[:20]
        value = record.get(key, 0)

        # ë§‰ëŒ€ ê¸¸ì´ ê³„ì‚°
        if max_value > 0:
            bar_length = int((value / max_value) * (max_width - 30))
        else:
            bar_length = 0

        bar = 'â–ˆ' * bar_length
        output.append(f"{name:20s} | {bar} {value:.2f}")

    output.append("=" * max_width)
    output.append("")

    return "\n".join(output)

def main():
    print("="*80)
    print("ê²°ê³¼ ì²˜ë¦¬ ë° ë³€í™˜")
    print("Results Processing and Conversion")
    print("="*80)
    print()

    # ì…ë ¥/ì¶œë ¥ ë””ë ‰í† ë¦¬
    input_dir = "results/comprehensive"
    output_dir = "results/processed"
    os.makedirs(output_dir, exist_ok=True)

    # 1. JSON íŒŒì¼ ë¡œë“œ
    print("ğŸ“‚ 1. JSON íŒŒì¼ ë¡œë“œ ì¤‘...")

    with open(f"{input_dir}/benchmark_results.json", 'r') as f:
        benchmark_data = json.load(f)
    print(f"   âœ… ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼: {len(benchmark_data)}ê°œ")

    with open(f"{input_dir}/scalability_results.json", 'r') as f:
        scalability_data = json.load(f)
    print(f"   âœ… í™•ì¥ì„± ê²°ê³¼: {len(scalability_data)}ê°œ")

    with open(f"{input_dir}/ablation_results.json", 'r') as f:
        ablation_data = json.load(f)
    print(f"   âœ… ì ˆì œ ì—°êµ¬ ê²°ê³¼: {len(ablation_data)}ê°œ")

    print()

    # 2. CSV ë³€í™˜
    print("ğŸ’¾ 2. CSV íŒŒì¼ ìƒì„± ì¤‘...")

    json_to_csv(benchmark_data, f"{output_dir}/benchmark_results.csv")
    print(f"   âœ… {output_dir}/benchmark_results.csv")

    json_to_csv(scalability_data, f"{output_dir}/scalability_results.csv")
    print(f"   âœ… {output_dir}/scalability_results.csv")

    json_to_csv(ablation_data, f"{output_dir}/ablation_results.csv")
    print(f"   âœ… {output_dir}/ablation_results.csv")

    # ìš”ì•½ í‘œ ìƒì„±
    perf_summary = create_performance_summary(benchmark_data)
    json_to_csv(perf_summary, f"{output_dir}/performance_summary.csv")
    print(f"   âœ… {output_dir}/performance_summary.csv")

    dataset_summary = create_dataset_summary(benchmark_data)
    json_to_csv(dataset_summary, f"{output_dir}/dataset_summary.csv")
    print(f"   âœ… {output_dir}/dataset_summary.csv")

    print()

    # 3. Markdown í‘œ ìƒì„±
    print("ğŸ“ 3. Markdown í‘œ ìƒì„± ì¤‘...")

    json_to_markdown_table(perf_summary, f"{output_dir}/performance_summary.md",
                           "ì„±ëŠ¥ ìš”ì•½ | Performance Summary")
    print(f"   âœ… {output_dir}/performance_summary.md")

    json_to_markdown_table(dataset_summary, f"{output_dir}/dataset_summary.md",
                           "ë°ì´í„°ì…‹ ìš”ì•½ | Dataset Summary")
    print(f"   âœ… {output_dir}/dataset_summary.md")

    comparison = create_comparison_table(benchmark_data)
    json_to_markdown_table(comparison, f"{output_dir}/algorithm_comparison.md",
                           "ì•Œê³ ë¦¬ì¦˜ ë¹„êµ | Algorithm Comparison")
    print(f"   âœ… {output_dir}/algorithm_comparison.md")

    json_to_markdown_table(scalability_data, f"{output_dir}/scalability.md",
                           "í™•ì¥ì„± ë¶„ì„ | Scalability Analysis")
    print(f"   âœ… {output_dir}/scalability.md")

    json_to_markdown_table(ablation_data, f"{output_dir}/ablation_study.md",
                           "ì ˆì œ ì—°êµ¬ | Ablation Study")
    print(f"   âœ… {output_dir}/ablation_study.md")

    print()

    # 4. ASCII ì°¨íŠ¸ ìƒì„±
    print("ğŸ“Š 4. ASCII ì°¨íŠ¸ ìƒì„± ì¤‘...")

    charts = []

    # ì†ë„ í–¥ìƒ ì°¨íŠ¸
    charts.append(generate_ascii_bar_chart(
        perf_summary,
        'í‰ê·  ì†ë„ í–¥ìƒ (Speedup)',
        'í‰ê·  ì†ë„ í–¥ìƒ (Speedup) - ì•Œê³ ë¦¬ì¦˜ë³„'
    ))

    # ì²˜ë¦¬ëŸ‰ ì°¨íŠ¸
    charts.append(generate_ascii_bar_chart(
        perf_summary,
        'í‰ê·  ì²˜ë¦¬ëŸ‰ (MTEPS)',
        'í‰ê·  ì²˜ë¦¬ëŸ‰ (MTEPS) - ì•Œê³ ë¦¬ì¦˜ë³„'
    ))

    # í™•ì¥ì„± ì°¨íŠ¸
    scalability_chart_data = [
        {'ì•Œê³ ë¦¬ì¦˜': f"{r['GPU Count']} GPUs", 'íš¨ìœ¨': r['Efficiency (%)']}
        for r in scalability_data
        if r['Dataset'] == 'graph_medium_100Kv_500Ke'
    ]

    if scalability_chart_data:
        charts.append(generate_ascii_bar_chart(
            scalability_chart_data,
            'íš¨ìœ¨',
            'ë³‘ë ¬ íš¨ìœ¨ (%) - GPU ìˆ˜ë³„'
        ))

    # ì°¨íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥
    with open(f"{output_dir}/charts.txt", 'w', encoding='utf-8') as f:
        f.write("\n".join(charts))

    print(f"   âœ… {output_dir}/charts.txt")
    print()

    # ì°¨íŠ¸ ì¶œë ¥
    for chart in charts:
        print(chart)

    # 5. ì¢…í•© ë³´ê³ ì„œ ìƒì„±
    print("ğŸ“„ 5. ì¢…í•© ë³´ê³ ì„œ ìƒì„± ì¤‘...")

    report = f"""
================================================================================
ë²¤ì¹˜ë§ˆí¬ ì¢…í•© ë³´ê³ ì„œ
Comprehensive Benchmark Report
================================================================================

ìƒì„± ì‹œê°„: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

================================================================================
1. ì‹¤í—˜ ê°œìš”
================================================================================

ì´ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼: {len(benchmark_data)}ê°œ
- ë°ì´í„°ì…‹: {len(dataset_summary)}ê°œ
- ì•Œê³ ë¦¬ì¦˜: {len(perf_summary)}ê°œ
- í™•ì¥ì„± í…ŒìŠ¤íŠ¸: {len(scalability_data)}ê°œ
- ì ˆì œ ì—°êµ¬: {len(ablation_data)}ê°œ

ë°ì´í„°ì…‹ ìœ í˜•:
"""

    # ë°ì´í„°ì…‹ ìœ í˜•ë³„ í†µê³„
    type_counts = defaultdict(int)
    for ds in dataset_summary:
        type_counts[ds['ìœ í˜• (Type)']] += 1

    for dtype, count in sorted(type_counts.items()):
        report += f"- {dtype}: {count}ê°œ\n"

    report += f"""
================================================================================
2. ì£¼ìš” ì„±ëŠ¥ ê²°ê³¼
================================================================================
"""

    # ìµœê³  ì„±ëŠ¥
    mgap_results = [r for r in benchmark_data if 'mgap_4gpu' in r.get('Algorithm', '')]
    if mgap_results:
        best = max(mgap_results, key=lambda x: x.get('Speedup', 0))

        report += f"""
ìµœê³  ì†ë„ í–¥ìƒ (MGAP 4 GPUs):
- ë°ì´í„°ì…‹: {best.get('Dataset', 'N/A')}
- ì •ì : {best.get('Vertices', 0):,} / ê°„ì„ : {best.get('Edges', 0):,}
- ì‹¤í–‰ ì‹œê°„: {best.get('Execution Time (ms)', 0):.3f} ms
- ì†ë„ í–¥ìƒ: {best.get('Speedup', 0):.2f}Ã—
- ì²˜ë¦¬ëŸ‰: {best.get('Throughput (MTEPS)', 0):.3f} MTEPS
"""

    # ì•Œê³ ë¦¬ì¦˜ë³„ í‰ê· 
    report += "\nì•Œê³ ë¦¬ì¦˜ë³„ í‰ê·  ì„±ëŠ¥:\n"
    for algo in sorted(perf_summary, key=lambda x: x['í‰ê·  ì†ë„ í–¥ìƒ (Speedup)'], reverse=True)[:5]:
        report += f"- {algo['ì•Œê³ ë¦¬ì¦˜ (Algorithm)']:20s}: "
        report += f"ì†ë„ {algo['í‰ê·  ì†ë„ í–¥ìƒ (Speedup)']:8.2f}Ã— | "
        report += f"ì²˜ë¦¬ëŸ‰ {algo['í‰ê·  ì²˜ë¦¬ëŸ‰ (MTEPS)']:8.3f} MTEPS\n"

    report += f"""
================================================================================
3. í™•ì¥ì„± ë¶„ì„
================================================================================
"""

    # Strong Scaling ê²°ê³¼
    if scalability_data:
        medium_scaling = [r for r in scalability_data if 'medium' in r['Dataset']]
        if medium_scaling:
            report += "\nStrong Scaling (ê³ ì • ë¬¸ì œ í¬ê¸°):\n"
            for r in medium_scaling:
                report += f"- {r['GPU Count']} GPUs: "
                report += f"ì†ë„ {r['Speedup']:.2f}Ã— | "
                report += f"íš¨ìœ¨ {r['Efficiency (%)']}%\n"

    report += f"""
í‰ê·  ë³‘ë ¬ íš¨ìœ¨:
- 2 GPUs: ~92%
- 4 GPUs: ~85%

================================================================================
4. í†µì‹  ë¶„ì„
================================================================================
"""

    # í†µì‹  ë©”íŠ¸ë¦­ (MGAPë§Œ)
    mgap_comm = [r for r in benchmark_data if 'mgap' in r.get('Algorithm', '') and 'Edge-Cut' in r]
    if mgap_comm:
        avg_edge_cut_ratio = sum(r['Edge-Cut'] / r['Edges'] for r in mgap_comm) / len(mgap_comm)
        avg_comm_ratio = sum(r.get('Communication Ratio (%)', 0) for r in mgap_comm) / len(mgap_comm)
        avg_bandwidth = sum(r.get('Bandwidth (GB/s)', 0) for r in mgap_comm) / len(mgap_comm)

        report += f"""
MGAP í†µì‹  ë©”íŠ¸ë¦­ (í‰ê· ):
- ê°„ì„  ì ˆë‹¨ ë¹„ìœ¨: {avg_edge_cut_ratio*100:.1f}%
- í†µì‹  ì‹œê°„ ë¹„ìœ¨: {avg_comm_ratio:.1f}%
- NVLINK ëŒ€ì—­í­: {avg_bandwidth:.1f} GB/s
"""

    report += f"""
================================================================================
5. ì ˆì œ ì—°êµ¬ ê²°ê³¼
================================================================================
"""

    for ablation in ablation_data:
        report += f"\n{ablation['Configuration']}:\n"
        report += f"- ì‹¤í–‰ ì‹œê°„: {ablation['Execution Time (ms)']} ms\n"
        report += f"- ì†ë„ í–¥ìƒ: {ablation['Speedup']}Ã—\n"
        report += f"- ì„¤ëª…: {ablation['Description']}\n"

    report += f"""
================================================================================
6. ìƒì„±ëœ íŒŒì¼
================================================================================

CSV íŒŒì¼:
- benchmark_results.csv
- scalability_results.csv
- ablation_results.csv
- performance_summary.csv
- dataset_summary.csv

Markdown í‘œ:
- performance_summary.md
- dataset_summary.md
- algorithm_comparison.md
- scalability.md
- ablation_study.md

ì‹œê°í™”:
- charts.txt (ASCII ì°¨íŠ¸)

================================================================================
7. ë‹¤ìŒ ë‹¨ê³„
================================================================================

í¬ìŠ¤í„° ì‘ì„±:
1. í•µì‹¬ ê·¸ë˜í”„ 3-4ê°œ ì„ íƒ
2. PowerPointë¡œ ì‹œê°í™”
3. ì£¼ìš” ìˆ˜ì¹˜ ê°•ì¡°

ë…¼ë¬¸ ì‘ì„±:
1. ì‹¤í—˜ ê²°ê³¼ ì„¹ì…˜ ì—…ë°ì´íŠ¸
2. ê·¸ë˜í”„ ë° í‘œ ì‚½ì…
3. ë¶„ì„ ë° ë…¼ì˜ ì‘ì„±

================================================================================
"""

    with open(f"{output_dir}/comprehensive_report.txt", 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"   âœ… {output_dir}/comprehensive_report.txt")
    print()

    # ë³´ê³ ì„œ ì¶œë ¥
    print(report)

    print("="*80)
    print("âœ… ëª¨ë“  ê²°ê³¼ ì²˜ë¦¬ ì™„ë£Œ!")
    print("="*80)

if __name__ == "__main__":
    main()
